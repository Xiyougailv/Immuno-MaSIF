1AO7_AC_DE_A6
正在处理 1AO7_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 3000 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2089  0.999998  0.000001  0.000000  ...  0.999998        0  999998.000000
1721  0.999997  0.000001  0.000000  ...  0.999997        0  499998.500000
2441  0.999996  0.000002  0.000001  ...  0.999996        0  499998.000000
2384  0.999996  0.000001  0.000002  ...  0.999996        0  499998.000000
1955  0.999996  0.000002  0.000000  ...  0.999996        0  499998.000000
...        ...       ...       ...  ...       ...      ...            ...
835   0.999279  0.000360  0.000000  ...  0.999279        0    2775.775000
1978  0.999393  0.000180  0.000004  ...  0.999393        0    2768.401662
2058  0.999567  0.000362  0.000004  ...  0.999567        0    2761.234807
868   0.999519  0.000080  0.000000  ...  0.999519        0    2761.102210
192   0.999206  0.000305  0.000002  ...  0.999206        0    2752.633609

[900 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 900 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 296，原始频次区间为 58 ~ 137；已标准化到[0, 1]区间

** 5. vertpool中共有 296 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 3000 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2089  0.999998  0.000001  0.000000  ...  0.999998        0  999998.000000
1721  0.999997  0.000001  0.000000  ...  0.999997        0  499998.500000
2441  0.999996  0.000002  0.000001  ...  0.999996        0  499998.000000
2384  0.999996  0.000001  0.000002  ...  0.999996        0  499998.000000
1955  0.999996  0.000002  0.000000  ...  0.999996        0  499998.000000
...        ...       ...       ...  ...       ...      ...            ...
835   0.999279  0.000360  0.000000  ...  0.999279        0    2775.775000
1978  0.999393  0.000180  0.000004  ...  0.999393        0    2768.401662
2058  0.999567  0.000362  0.000004  ...  0.999567        0    2761.234807
868   0.999519  0.000080  0.000000  ...  0.999519        0    2761.102210
192   0.999206  0.000305  0.000002  ...  0.999206        0    2752.633609

[900 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：2752.633609 ~ 999998.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.744313
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.104996

** 3. 抽取的sample.csv形状为： 900 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 296，加权重的“原始”频次区间为 55.762153 ~ 139.433836；已标准化：线性缩放

** 5. vertpool中共有 296 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//1AO7_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 1: 1AO7_AC_DE_A6 处理完成^_^
1QRN_AC_DE_A6
正在处理 1QRN_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 1000 次，正确预测 999 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
            0         1    2  ...   max_val  max_idx     confidence
900  0.999992  0.000003  0.0  ...  0.999992        0  249998.000000
513  0.999992  0.000001  0.0  ...  0.999992        0  166665.333333
506  0.999990  0.000003  0.0  ...  0.999990        0  166665.000000
557  0.999991  0.000001  0.0  ...  0.999991        0  142855.857143
854  0.999990  0.000002  0.0  ...  0.999990        0  142855.714286
..        ...       ...  ...  ...       ...      ...            ...
898  0.999743  0.000025  0.0  ...  0.999743        0    5100.729592
732  0.999662  0.000017  0.0  ...  0.999662        0    5074.426396
791  0.999748  0.000005  0.0  ...  0.999748        0    4998.740000
866  0.999750  0.000013  0.0  ...  0.999750        0    4973.880597
704  0.999679  0.000043  0.0  ...  0.999679        0    4973.527363

[299 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 299 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 286，原始频次区间为 15 ~ 52；已标准化到[0, 1]区间

** 5. vertpool中共有 286 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 1000 次，正确预测 999 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
            0         1    2  ...   max_val  max_idx     confidence
900  0.999992  0.000003  0.0  ...  0.999992        0  249998.000000
513  0.999992  0.000001  0.0  ...  0.999992        0  166665.333333
506  0.999990  0.000003  0.0  ...  0.999990        0  166665.000000
557  0.999991  0.000001  0.0  ...  0.999991        0  142855.857143
854  0.999990  0.000002  0.0  ...  0.999990        0  142855.714286
..        ...       ...  ...  ...       ...      ...            ...
898  0.999743  0.000025  0.0  ...  0.999743        0    5100.729592
732  0.999662  0.000017  0.0  ...  0.999662        0    5074.426396
791  0.999748  0.000005  0.0  ...  0.999748        0    4998.740000
866  0.999750  0.000013  0.0  ...  0.999750        0    4973.880597
704  0.999679  0.000043  0.0  ...  0.999679        0    4973.527363

[299 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：4973.527363 ~ 249998.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.460218
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：1.584420

** 3. 抽取的sample.csv形状为： 299 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 286，加权重的“原始”频次区间为 13.842354 ~ 52.207684；已标准化：线性缩放

** 5. vertpool中共有 286 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//1QRN_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 2: 1QRN_AC_DE_A6 处理完成^_^
1QSE_AC_DE_A6
正在处理 1QSE_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 2025 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2931  0.999998  0.000001  0.000000  ...  0.999998        0  999998.000000
2567  0.999997  0.000002  0.000000  ...  0.999997        0  499998.500000
2589  0.999995  0.000003  0.000000  ...  0.999995        0  333331.666667
2764  0.999994  0.000004  0.000000  ...  0.999994        0  249998.500000
2802  0.999992  0.000001  0.000000  ...  0.999992        0  166665.333333
...        ...       ...       ...  ...       ...      ...            ...
2776  0.989619  0.005503  0.000000  ...  0.989619        0     179.832637
903   0.994091  0.005535  0.000231  ...  0.994091        0     179.600903
790   0.994406  0.005580  0.000010  ...  0.994406        0     178.208961
2760  0.991638  0.002766  0.000000  ...  0.991638        0     177.204789
2955  0.992318  0.002037  0.000000  ...  0.992318        0     175.787068

[607 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 607 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 328，原始频次区间为 33 ~ 87；已标准化到[0, 1]区间

** 5. vertpool中共有 328 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 2025 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2931  0.999998  0.000001  0.000000  ...  0.999998        0  999998.000000
2567  0.999997  0.000002  0.000000  ...  0.999997        0  499998.500000
2589  0.999995  0.000003  0.000000  ...  0.999995        0  333331.666667
2764  0.999994  0.000004  0.000000  ...  0.999994        0  249998.500000
2802  0.999992  0.000001  0.000000  ...  0.999992        0  166665.333333
...        ...       ...       ...  ...       ...      ...            ...
2776  0.989619  0.005503  0.000000  ...  0.989619        0     179.832637
903   0.994091  0.005535  0.000231  ...  0.994091        0     179.600903
790   0.994406  0.005580  0.000010  ...  0.994406        0     178.208961
2760  0.991638  0.002766  0.000000  ...  0.991638        0     177.204789
2955  0.992318  0.002037  0.000000  ...  0.992318        0     175.787068

[607 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：175.787068 ~ 999998.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.672621
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：5.326109

** 3. 抽取的sample.csv形状为： 607 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 328，加权重的“原始”频次区间为 28.973645 ~ 87.866765；已标准化：线性缩放

** 5. vertpool中共有 328 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//1QSE_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 3: 1QSE_AC_DE_A6 处理完成^_^
1QSF_AC_DE_A6
正在处理 1QSF_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 3731 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1566  0.999917  0.000032  0.000018  ...  0.999917        0  31247.406250
1754  0.999916  0.000001  0.000045  ...  0.999916        0  22220.355556
1680  0.999848  0.000010  0.000055  ...  0.999848        0  14923.104478
1980  0.999810  0.000003  0.000077  ...  0.999810        0  12984.545455
1792  0.999817  0.000016  0.000039  ...  0.999817        0  10414.760417
...        ...       ...       ...  ...       ...      ...           ...
3988  0.975727  0.002657  0.000616  ...  0.975727        0     66.743758
2118  0.982401  0.014721  0.001997  ...  0.982401        0     66.734665
2378  0.969074  0.014541  0.007590  ...  0.969074        0     66.644247
2236  0.967419  0.014522  0.003880  ...  0.967419        0     66.617477
2581  0.981988  0.000722  0.002235  ...  0.981988        0     66.530352

[1119 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1119 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 262，原始频次区间为 80 ~ 221；已标准化到[0, 1]区间

** 5. vertpool中共有 262 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 3731 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1566  0.999917  0.000032  0.000018  ...  0.999917        0  31247.406250
1754  0.999916  0.000001  0.000045  ...  0.999916        0  22220.355556
1680  0.999848  0.000010  0.000055  ...  0.999848        0  14923.104478
1980  0.999810  0.000003  0.000077  ...  0.999810        0  12984.545455
1792  0.999817  0.000016  0.000039  ...  0.999817        0  10414.760417
...        ...       ...       ...  ...       ...      ...           ...
3988  0.975727  0.002657  0.000616  ...  0.975727        0     66.743758
2118  0.982401  0.014721  0.001997  ...  0.982401        0     66.734665
2378  0.969074  0.014541  0.007590  ...  0.969074        0     66.644247
2236  0.967419  0.014522  0.003880  ...  0.967419        0     66.617477
2581  0.981988  0.000722  0.002235  ...  0.981988        0     66.530352

[1119 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：66.530352 ~ 31247.406250
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.465587
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：4.330084

** 3. 抽取的sample.csv形状为： 1119 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 262，加权重的“原始”频次区间为 72.666813 ~ 228.811299；已标准化：线性缩放

** 5. vertpool中共有 262 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//1QSF_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 4: 1QSF_AC_DE_A6 处理完成^_^
2GJ6_AC_DE_A6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 2GJ6_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2999 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1    2    3  ...   sec_val   max_val  max_idx  confidence
1500  1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
594   0.999999  0.000000  0.0  0.0  ...  0.000000  0.999999        0         inf
584   1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
585   1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
586   1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
...        ...       ...  ...  ...  ...       ...       ...      ...         ...
2173  0.999999  0.000001  0.0  0.0  ...  0.000001  0.999999        0    999999.0
2169  0.999999  0.000001  0.0  0.0  ...  0.000001  0.999999        0    999999.0
1553  0.999999  0.000000  0.0  0.0  ...  0.000001  0.999999        0    999999.0
1554  0.999999  0.000000  0.0  0.0  ...  0.000001  0.999999        0    999999.0
1951  0.999999  0.000000  0.0  0.0  ...  0.000001  0.999999        0    999999.0

[899 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 899 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 300，原始频次区间为 49 ~ 136；已标准化到[0, 1]区间

** 5. vertpool中共有 300 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2999 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1    2    3  ...   sec_val   max_val  max_idx  confidence
1500  1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
594   0.999999  0.000000  0.0  0.0  ...  0.000000  0.999999        0         inf
584   1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
585   1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
586   1.000000  0.000000  0.0  0.0  ...  0.000000  1.000000        0         inf
...        ...       ...  ...  ...  ...       ...       ...      ...         ...
2173  0.999999  0.000001  0.0  0.0  ...  0.000001  0.999999        0    999999.0
2169  0.999999  0.000001  0.0  0.0  ...  0.000001  0.999999        0    999999.0
1553  0.999999  0.000000  0.0  0.0  ...  0.000001  0.999999        0    999999.0
1554  0.999999  0.000000  0.0  0.0  ...  0.000001  0.999999        0    999999.0
1951  0.999999  0.000000  0.0  0.0  ...  0.000001  0.999999        0    999999.0

[899 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：999999.000000 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 899 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 300，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 300 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//2GJ6_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 5: 2GJ6_AC_DE_A6 处理完成^_^
3QFJ_AC_DE_A6
正在处理 3QFJ_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3355 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
1332  0.999998  0.000001  0.000000  ...  0.999998        0  499999.000000
2869  0.999995  0.000002  0.000000  ...  0.999995        0  499997.500000
1281  0.999994  0.000003  0.000000  ...  0.999994        0  333331.333333
2798  0.999991  0.000001  0.000001  ...  0.999991        0  249997.750000
2707  0.999988  0.000005  0.000000  ...  0.999988        0  199997.600000
...        ...       ...       ...  ...       ...      ...            ...
2613  0.998878  0.000108  0.000018  ...  0.998878        0    1245.483791
3471  0.998766  0.000008  0.000024  ...  0.998766        0    1222.479804
3476  0.999018  0.000001  0.000024  ...  0.999018        0    1219.802198
970   0.998923  0.000062  0.000099  ...  0.998923        0    1216.714982
357   0.998942  0.000009  0.000018  ...  0.998942        0    1213.781288

[1006 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1006 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 301，原始频次区间为 61 ~ 153；已标准化到[0, 1]区间

** 5. vertpool中共有 301 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3355 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
1332  0.999998  0.000001  0.000000  ...  0.999998        0  499999.000000
2869  0.999995  0.000002  0.000000  ...  0.999995        0  499997.500000
1281  0.999994  0.000003  0.000000  ...  0.999994        0  333331.333333
2798  0.999991  0.000001  0.000001  ...  0.999991        0  249997.750000
2707  0.999988  0.000005  0.000000  ...  0.999988        0  199997.600000
...        ...       ...       ...  ...       ...      ...            ...
2613  0.998878  0.000108  0.000018  ...  0.998878        0    1245.483791
3471  0.998766  0.000008  0.000024  ...  0.998766        0    1222.479804
3476  0.999018  0.000001  0.000024  ...  0.999018        0    1219.802198
970   0.998923  0.000062  0.000099  ...  0.998923        0    1216.714982
357   0.998942  0.000009  0.000018  ...  0.998942        0    1213.781288

[1006 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：1213.781288 ~ 499999.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.847831
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.334577

** 3. 抽取的sample.csv形状为： 1006 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 301，加权重的“原始”频次区间为 59.926625 ~ 158.596737；已标准化：线性缩放

** 5. vertpool中共有 301 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3QFJ_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 6: 3QFJ_AC_DE_A6 处理完成^_^
3PWP_AC_DE_A6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 3PWP_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3498 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1434  0.999999  0.000000  0.000000  ...  0.999999        0           inf
2183  0.999997  0.000001  0.000002  ...  0.999997        0  4.999985e+05
1015  0.999994  0.000000  0.000001  ...  0.999994        0  3.333313e+05
1396  0.999992  0.000000  0.000002  ...  0.999992        0  2.499980e+05
2452  0.999995  0.000000  0.000005  ...  0.999995        0  1.999990e+05
...        ...       ...       ...  ...       ...      ...           ...
3240  0.999294  0.000000  0.000247  ...  0.999294        0  2.588845e+03
2706  0.999570  0.000023  0.000387  ...  0.999570        0  2.582868e+03
1719  0.999353  0.000182  0.000015  ...  0.999353        0  2.582307e+03
1370  0.999364  0.000000  0.000017  ...  0.999364        0  2.569059e+03
2328  0.999364  0.000005  0.000149  ...  0.999364        0  2.569059e+03

[1049 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1049 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 277，原始频次区间为 74 ~ 165；已标准化到[0, 1]区间

** 5. vertpool中共有 277 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3498 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1434  0.999999  0.000000  0.000000  ...  0.999999        0           inf
2183  0.999997  0.000001  0.000002  ...  0.999997        0  4.999985e+05
1015  0.999994  0.000000  0.000001  ...  0.999994        0  3.333313e+05
1396  0.999992  0.000000  0.000002  ...  0.999992        0  2.499980e+05
2452  0.999995  0.000000  0.000005  ...  0.999995        0  1.999990e+05
...        ...       ...       ...  ...       ...      ...           ...
3240  0.999294  0.000000  0.000247  ...  0.999294        0  2.588845e+03
2706  0.999570  0.000023  0.000387  ...  0.999570        0  2.582868e+03
1719  0.999353  0.000182  0.000015  ...  0.999353        0  2.582307e+03
1370  0.999364  0.000000  0.000017  ...  0.999364        0  2.569059e+03
2328  0.999364  0.000005  0.000149  ...  0.999364        0  2.569059e+03

[1049 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：2569.059126 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 1049 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 277，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 277 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3PWP_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 7: 3PWP_AC_DE_A6 处理完成^_^
3H9S_AC_DE_A6
正在处理 3H9S_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4500 次，正确预测 3937 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
61    0.999975  0.000011  0.000002  ...  0.999975        0  90906.818182
1186  0.999973  0.000005  0.000011  ...  0.999973        0  90906.636364
4217  0.999975  0.000009  0.000000  ...  0.999975        0  62498.437500
4463  0.999962  0.000011  0.000000  ...  0.999962        0  38460.076923
4491  0.999957  0.000026  0.000000  ...  0.999957        0  38459.884615
...        ...       ...       ...  ...       ...      ...           ...
251   0.985370  0.006305  0.006278  ...  0.985370        0    156.283902
819   0.990522  0.000605  0.006345  ...  0.990522        0    156.110638
3698  0.993428  0.000192  0.000002  ...  0.993428        0    156.003141
1674  0.991080  0.000100  0.001394  ...  0.991080        0    155.928257
2351  0.991576  0.002022  0.000004  ...  0.991576        0    155.761232

[1181 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1181 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 286，原始频次区间为 67 ~ 192；已标准化到[0, 1]区间

** 5. vertpool中共有 286 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4500 次，正确预测 3937 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
61    0.999975  0.000011  0.000002  ...  0.999975        0  90906.818182
1186  0.999973  0.000005  0.000011  ...  0.999973        0  90906.636364
4217  0.999975  0.000009  0.000000  ...  0.999975        0  62498.437500
4463  0.999962  0.000011  0.000000  ...  0.999962        0  38460.076923
4491  0.999957  0.000026  0.000000  ...  0.999957        0  38459.884615
...        ...       ...       ...  ...       ...      ...           ...
251   0.985370  0.006305  0.006278  ...  0.985370        0    156.283902
819   0.990522  0.000605  0.006345  ...  0.990522        0    156.110638
3698  0.993428  0.000192  0.000002  ...  0.993428        0    156.003141
1674  0.991080  0.000100  0.001394  ...  0.991080        0    155.928257
2351  0.991576  0.002022  0.000004  ...  0.991576        0    155.761232

[1181 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：155.761232 ~ 90906.818182
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.261659
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：3.531277

** 3. 抽取的sample.csv形状为： 1181 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 286，加权重的“原始”频次区间为 64.317677 ~ 202.121294；已标准化：线性缩放

** 5. vertpool中共有 286 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3H9S_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 8: 3H9S_AC_DE_A6 处理完成^_^
1OGA_AC_DE_JM22
正在处理 1OGA_AC_DE_JM22 ... 其TCR标签为 3 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3371 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
2008  0.000009  0.000000  0.000022  ...  0.999969        3  45453.136364
2160  0.000001  0.000000  0.000029  ...  0.999970        3  34481.724138
2213  0.000001  0.000000  0.000031  ...  0.999967        3  32257.000000
2279  0.000037  0.000000  0.000031  ...  0.999927        3  27025.054054
2249  0.000004  0.000000  0.000038  ...  0.999957        3  26314.657895
...        ...       ...       ...  ...       ...      ...           ...
281   0.002495  0.000038  0.008450  ...  0.982355        3    116.255030
1678  0.000096  0.000000  0.008519  ...  0.990133        3    116.226435
216   0.008444  0.000029  0.006984  ...  0.980042        3    116.063714
2709  0.000267  0.000002  0.008546  ...  0.989725        3    115.811491
1971  0.000040  0.000000  0.008550  ...  0.989779        3    115.763626

[1011 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1011 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 229，原始频次区间为 99 ~ 202；已标准化到[0, 1]区间

** 5. vertpool中共有 229 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3371 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
2008  0.000009  0.000000  0.000022  ...  0.999969        3  45453.136364
2160  0.000001  0.000000  0.000029  ...  0.999970        3  34481.724138
2213  0.000001  0.000000  0.000031  ...  0.999967        3  32257.000000
2279  0.000037  0.000000  0.000031  ...  0.999927        3  27025.054054
2249  0.000004  0.000000  0.000038  ...  0.999957        3  26314.657895
...        ...       ...       ...  ...       ...      ...           ...
281   0.002495  0.000038  0.008450  ...  0.982355        3    116.255030
1678  0.000096  0.000000  0.008519  ...  0.990133        3    116.226435
216   0.008444  0.000029  0.006984  ...  0.980042        3    116.063714
2709  0.000267  0.000002  0.008546  ...  0.989725        3    115.811491
1971  0.000040  0.000000  0.008550  ...  0.989779        3    115.763626

[1011 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：115.763626 ~ 45453.136364
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.257040
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：3.515000

** 3. 抽取的sample.csv形状为： 1011 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 229，加权重的“原始”频次区间为 98.494147 ~ 205.831901；已标准化：线性缩放

** 5. vertpool中共有 229 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//1OGA_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 9: 1OGA_AC_DE_JM22 处理完成^_^
5HHO_AC_DE_JM22
正在处理 5HHO_AC_DE_JM22 ... 其TCR标签为 3 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 220 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
2785  0.000026  0.000000  0.000972  ...  0.992037        3  178.745405
2965  0.002035  0.000018  0.013444  ...  0.967846        3   71.990925
2531  0.006419  0.000007  0.019135  ...  0.957536        3   50.041077
2817  0.004004  0.000022  0.006677  ...  0.956479        3   34.390874
2924  0.001001  0.000011  0.011548  ...  0.948675        3   31.894668
...        ...       ...       ...  ...       ...      ...         ...
2867  0.014913  0.005328  0.027585  ...  0.646300        3    3.570225
2703  0.163402  0.001231  0.088925  ...  0.580547        3    3.552876
2442  0.103350  0.026382  0.022698  ...  0.594209        3    3.550908
2830  0.007905  0.000485  0.075443  ...  0.587176        3    3.435727
2717  0.013946  0.000795  0.085007  ...  0.632669        3    3.421589

[66 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 66 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 254，原始频次区间为 1 ~ 20；已标准化到[0, 1]区间

** 5. vertpool中共有 254 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 220 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
2785  0.000026  0.000000  0.000972  ...  0.992037        3  178.745405
2965  0.002035  0.000018  0.013444  ...  0.967846        3   71.990925
2531  0.006419  0.000007  0.019135  ...  0.957536        3   50.041077
2817  0.004004  0.000022  0.006677  ...  0.956479        3   34.390874
2924  0.001001  0.000011  0.011548  ...  0.948675        3   31.894668
...        ...       ...       ...  ...       ...      ...         ...
2867  0.014913  0.005328  0.027585  ...  0.646300        3    3.570225
2703  0.163402  0.001231  0.088925  ...  0.580547        3    3.552876
2442  0.103350  0.026382  0.022698  ...  0.594209        3    3.550908
2830  0.007905  0.000485  0.075443  ...  0.587176        3    3.435727
2717  0.013946  0.000795  0.085007  ...  0.632669        3    3.421589

[66 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3.421589 ~ 178.745405
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 4.215869
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：24.924944

** 3. 抽取的sample.csv形状为： 66 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 254，加权重的“原始”频次区间为 0.421909 ~ 25.231776；已标准化：线性缩放

** 5. vertpool中共有 254 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5HHO_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 10: 5HHO_AC_DE_JM22 处理完成^_^
5HHM_AC_DE_JM22
正在处理 5HHM_AC_DE_JM22 ... 其TCR标签为 3 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 5500 次，正确预测 4777 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
3220  0.000003  0.000000  0.000007  ...  0.999981        3  111109.000000
3481  0.000002  0.000000  0.000009  ...  0.999974        3   62498.375000
3312  0.000009  0.000000  0.000011  ...  0.999962        3   55553.444444
3114  0.000015  0.000000  0.000022  ...  0.999924        3   25639.076923
3310  0.000003  0.000000  0.000054  ...  0.999928        3   18517.185185
...        ...       ...       ...  ...       ...      ...            ...
3297  0.000356  0.000000  0.022087  ...  0.971284        3      43.975370
2399  0.000772  0.000008  0.017762  ...  0.959617        3      43.966691
124   0.004153  0.000000  0.000136  ...  0.973499        3      43.829589
2719  0.000035  0.000000  0.022351  ...  0.977242        3      43.722518
3457  0.000005  0.000000  0.022054  ...  0.961034        3      43.576403

[1433 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1433 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 241，原始频次区间为 132 ~ 263；已标准化到[0, 1]区间

** 5. vertpool中共有 241 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 5500 次，正确预测 4777 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
3220  0.000003  0.000000  0.000007  ...  0.999981        3  111109.000000
3481  0.000002  0.000000  0.000009  ...  0.999974        3   62498.375000
3312  0.000009  0.000000  0.000011  ...  0.999962        3   55553.444444
3114  0.000015  0.000000  0.000022  ...  0.999924        3   25639.076923
3310  0.000003  0.000000  0.000054  ...  0.999928        3   18517.185185
...        ...       ...       ...  ...       ...      ...            ...
3297  0.000356  0.000000  0.022087  ...  0.971284        3      43.975370
2399  0.000772  0.000008  0.017762  ...  0.959617        3      43.966691
124   0.004153  0.000000  0.000136  ...  0.973499        3      43.829589
2719  0.000035  0.000000  0.022351  ...  0.977242        3      43.722518
3457  0.000005  0.000000  0.022054  ...  0.961034        3      43.576403

[1433 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：43.576403 ~ 111109.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.078081
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：7.989127

** 3. 抽取的sample.csv形状为： 1433 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 241，加权重的“原始”频次区间为 122.916994 ~ 277.820085；已标准化：线性缩放

** 5. vertpool中共有 241 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5HHM_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 11: 5HHM_AC_DE_JM22 处理完成^_^
5NME_AC_DE_868
正在处理 5NME_AC_DE_868 ... 其TCR标签为 5 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2572 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
1646  0.000952  0.000405  0.000000  ...  0.998643        5  1048.994748
1815  0.001443  0.001683  0.000000  ...  0.996873        5   592.319073
1514  0.000714  0.001722  0.000000  ...  0.997564        5   579.305459
1949  0.001624  0.001897  0.000000  ...  0.996479        5   525.292040
1549  0.001669  0.002324  0.000000  ...  0.996007        5   428.574441
...        ...       ...       ...  ...       ...      ...          ...
443   0.057080  0.038978  0.009191  ...  0.894596        5    15.672670
583   0.011578  0.057114  0.025883  ...  0.894801        5    15.666929
978   0.056939  0.005916  0.044173  ...  0.891462        5    15.656439
784   0.015084  0.013911  0.058352  ...  0.910945        5    15.611204
1542  0.059727  0.008718  0.000000  ...  0.931551        5    15.596816

[771 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 771 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 253，原始频次区间为 52 ~ 137；已标准化到[0, 1]区间

** 5. vertpool中共有 253 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2572 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
1646  0.000952  0.000405  0.000000  ...  0.998643        5  1048.994748
1815  0.001443  0.001683  0.000000  ...  0.996873        5   592.319073
1514  0.000714  0.001722  0.000000  ...  0.997564        5   579.305459
1949  0.001624  0.001897  0.000000  ...  0.996479        5   525.292040
1549  0.001669  0.002324  0.000000  ...  0.996007        5   428.574441
...        ...       ...       ...  ...       ...      ...          ...
443   0.057080  0.038978  0.009191  ...  0.894596        5    15.672670
583   0.011578  0.057114  0.025883  ...  0.894801        5    15.666929
978   0.056939  0.005916  0.044173  ...  0.891462        5    15.656439
784   0.015084  0.013911  0.058352  ...  0.910945        5    15.611204
1542  0.059727  0.008718  0.000000  ...  0.931551        5    15.596816

[771 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：15.596816 ~ 1048.994748
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.532005
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：4.627447

** 3. 抽取的sample.csv形状为： 771 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 253，加权重的“原始”频次区间为 48.794163 ~ 139.394523；已标准化：线性缩放

** 5. vertpool中共有 253 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5NME_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 12: 5NME_AC_DE_868 处理完成^_^
5NMF_AC_DE_868
正在处理 5NMF_AC_DE_868 ... 其TCR标签为 5 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2592 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
325   0.001074  0.001552  0.000000  ...  0.997371        5  642.635954
4     0.001389  0.001774  0.000000  ...  0.996835        5  561.913754
137   0.000531  0.002154  0.000000  ...  0.997315        5  463.006035
195   0.002206  0.001458  0.000000  ...  0.996335        5  451.647779
232   0.002711  0.002831  0.000000  ...  0.994446        5  351.270223
...        ...       ...       ...  ...       ...      ...         ...
817   0.001437  0.068972  0.008959  ...  0.809747        5   11.284257
2777  0.011390  0.010471  0.075151  ...  0.847851        5   11.281966
1967  0.003731  0.005069  0.057758  ...  0.857256        5   11.281020
1757  0.010184  0.020301  0.073583  ...  0.829367        5   11.271177
2413  0.020499  0.000138  0.079575  ...  0.893812        5   11.232322

[777 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 777 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 255，原始频次区间为 59 ~ 131；已标准化到[0, 1]区间

** 5. vertpool中共有 255 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2592 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
325   0.001074  0.001552  0.000000  ...  0.997371        5  642.635954
4     0.001389  0.001774  0.000000  ...  0.996835        5  561.913754
137   0.000531  0.002154  0.000000  ...  0.997315        5  463.006035
195   0.002206  0.001458  0.000000  ...  0.996335        5  451.647779
232   0.002711  0.002831  0.000000  ...  0.994446        5  351.270223
...        ...       ...       ...  ...       ...      ...         ...
817   0.001437  0.068972  0.008959  ...  0.809747        5   11.284257
2777  0.011390  0.010471  0.075151  ...  0.847851        5   11.281966
1967  0.003731  0.005069  0.057758  ...  0.857256        5   11.281020
1757  0.010184  0.020301  0.073583  ...  0.829367        5   11.271177
2413  0.020499  0.000138  0.079575  ...  0.893812        5   11.232322

[777 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：11.232322 ~ 642.635954
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.673057
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：5.328432

** 3. 抽取的sample.csv形状为： 777 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 255，加权重的“原始”频次区间为 55.437165 ~ 132.231964；已标准化：线性缩放

** 5. vertpool中共有 255 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5NMF_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 13: 5NMF_AC_DE_868 处理完成^_^
5NMG_AC_DE_868
正在处理 5NMG_AC_DE_868 ... 其TCR标签为 5 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 213 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
443   0.001221  0.000006  0.000010  ...  0.993472        5  187.837398
1606  0.010395  0.000100  0.022370  ...  0.964587        5   43.119669
1795  0.022181  0.000787  0.014231  ...  0.954513        5   43.032911
286   0.001642  0.000018  0.000239  ...  0.973793        5   40.065542
1820  0.007576  0.000105  0.024831  ...  0.966009        5   38.903347
...        ...       ...       ...  ...       ...      ...         ...
1954  0.015933  0.002487  0.148178  ...  0.814746        5    5.498428
50    0.003979  0.000042  0.002123  ...  0.834541        5    5.238768
1755  0.009975  0.000378  0.150511  ...  0.784856        5    5.214609
347   0.003294  0.000054  0.005335  ...  0.828821        5    5.101002
351   0.009533  0.000041  0.007931  ...  0.819753        5    5.037782

[63 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 63 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 252，原始频次区间为 1 ~ 18；已标准化到[0, 1]区间

** 5. vertpool中共有 252 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 213 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
443   0.001221  0.000006  0.000010  ...  0.993472        5  187.837398
1606  0.010395  0.000100  0.022370  ...  0.964587        5   43.119669
1795  0.022181  0.000787  0.014231  ...  0.954513        5   43.032911
286   0.001642  0.000018  0.000239  ...  0.973793        5   40.065542
1820  0.007576  0.000105  0.024831  ...  0.966009        5   38.903347
...        ...       ...       ...  ...       ...      ...         ...
1954  0.015933  0.002487  0.148178  ...  0.814746        5    5.498428
50    0.003979  0.000042  0.002123  ...  0.834541        5    5.238768
1755  0.009975  0.000378  0.150511  ...  0.784856        5    5.214609
347   0.003294  0.000054  0.005335  ...  0.828821        5    5.101002
351   0.009533  0.000041  0.007931  ...  0.819753        5    5.037782

[63 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：5.037782 ~ 187.837398
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.237902
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：9.373640

** 3. 抽取的sample.csv形状为： 63 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 252，加权重的“原始”频次区间为 0.560373 ~ 20.847606；已标准化：线性缩放

** 5. vertpool中共有 252 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5NMG_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 14: 5NMG_AC_DE_868 处理完成^_^
5HYJ_AC_DE_1E6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 5HYJ_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 5500 次，正确预测 5498 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
4645  0.000000  0.999999  0.000000  ...  0.999999        1         inf
2353  0.000000  1.000000  0.000000  ...  1.000000        1         inf
553   0.000000  0.999999  0.000000  ...  0.999999        1         inf
782   0.000000  1.000000  0.000000  ...  1.000000        1         inf
1931  0.000000  0.999999  0.000000  ...  0.999999        1         inf
...        ...       ...       ...  ...       ...      ...         ...
49    0.000003  0.999987  0.000000  ...  0.999987        1  124998.375
1193  0.000008  0.999987  0.000000  ...  0.999987        1  124998.375
1902  0.000001  0.999986  0.000008  ...  0.999986        1  124998.250
1640  0.000000  0.999986  0.000008  ...  0.999986        1  124998.250
2247  0.000000  0.999986  0.000000  ...  0.999986        1  124998.250

[1649 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1649 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 248，原始频次区间为 150 ~ 294；已标准化到[0, 1]区间

** 5. vertpool中共有 248 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 5500 次，正确预测 5498 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
4645  0.000000  0.999999  0.000000  ...  0.999999        1         inf
2353  0.000000  1.000000  0.000000  ...  1.000000        1         inf
553   0.000000  0.999999  0.000000  ...  0.999999        1         inf
782   0.000000  1.000000  0.000000  ...  1.000000        1         inf
1931  0.000000  0.999999  0.000000  ...  0.999999        1         inf
...        ...       ...       ...  ...       ...      ...         ...
49    0.000003  0.999987  0.000000  ...  0.999987        1  124998.375
1193  0.000008  0.999987  0.000000  ...  0.999987        1  124998.375
1902  0.000001  0.999986  0.000008  ...  0.999986        1  124998.250
1640  0.000000  0.999986  0.000008  ...  0.999986        1  124998.250
2247  0.000000  0.999986  0.000000  ...  0.999986        1  124998.250

[1649 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：124998.250000 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 1649 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 248，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 248 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5HYJ_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 15: 5HYJ_AC_DE_1E6 处理完成^_^
5C07_AC_DE_1E6
正在处理 5C07_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2281 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
1027  0.000000  0.999986  0.000007  ...  0.999986        1  142855.142857
1140  0.000001  0.999984  0.000000  ...  0.999984        1   90907.636364
1122  0.000004  0.999975  0.000002  ...  0.999975        1   83331.250000
1217  0.000001  0.999967  0.000012  ...  0.999967        1   83330.583333
1322  0.000001  0.999966  0.000013  ...  0.999966        1   76920.461538
...        ...       ...       ...  ...       ...      ...            ...
1909  0.000419  0.994211  0.001460  ...  0.994211        1     320.920271
117   0.000653  0.995038  0.000001  ...  0.995038        1     320.050820
281   0.000149  0.996676  0.000000  ...  0.996676        1     319.960193
2086  0.003182  0.996083  0.000062  ...  0.996083        1     313.036769
1835  0.000138  0.996026  0.000173  ...  0.996026        1     312.233856

[684 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 684 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 291，原始频次区间为 43 ~ 108；已标准化到[0, 1]区间

** 5. vertpool中共有 291 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2281 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
1027  0.000000  0.999986  0.000007  ...  0.999986        1  142855.142857
1140  0.000001  0.999984  0.000000  ...  0.999984        1   90907.636364
1122  0.000004  0.999975  0.000002  ...  0.999975        1   83331.250000
1217  0.000001  0.999967  0.000012  ...  0.999967        1   83330.583333
1322  0.000001  0.999966  0.000013  ...  0.999966        1   76920.461538
...        ...       ...       ...  ...       ...      ...            ...
1909  0.000419  0.994211  0.001460  ...  0.994211        1     320.920271
117   0.000653  0.995038  0.000001  ...  0.995038        1     320.050820
281   0.000149  0.996676  0.000000  ...  0.996676        1     319.960193
2086  0.003182  0.996083  0.000062  ...  0.996083        1     313.036769
1835  0.000138  0.996026  0.000173  ...  0.996026        1     312.233856

[684 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：312.233856 ~ 142855.142857
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.066521
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.905255

** 3. 抽取的sample.csv形状为： 684 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 291，加权重的“原始”频次区间为 42.923690 ~ 111.470160；已标准化：线性缩放

** 5. vertpool中共有 291 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5C07_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 16: 5C07_AC_DE_1E6 处理完成^_^
5C09_AC_DE_1E6
正在处理 5C09_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3448 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2991  0.000002  0.999998  0.000000  ...  0.999998        1  499999.000000
2933  0.000002  0.999998  0.000000  ...  0.999998        1  499999.000000
408   0.000003  0.999997  0.000000  ...  0.999997        1  333332.333333
2960  0.000006  0.999994  0.000000  ...  0.999994        1  166665.666667
2702  0.000006  0.999994  0.000000  ...  0.999994        1  166665.666667
...        ...       ...       ...  ...       ...      ...            ...
1844  0.003263  0.991121  0.000496  ...  0.991121        1     198.541867
695   0.005013  0.994452  0.000001  ...  0.994452        1     198.374626
452   0.005022  0.994813  0.000102  ...  0.994813        1     198.091000
2573  0.005043  0.994675  0.000086  ...  0.994675        1     197.238747
2333  0.005015  0.988224  0.000364  ...  0.988224        1     197.053639

[1034 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1034 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 290，原始频次区间为 68 ~ 173；已标准化到[0, 1]区间

** 5. vertpool中共有 290 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3448 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2991  0.000002  0.999998  0.000000  ...  0.999998        1  499999.000000
2933  0.000002  0.999998  0.000000  ...  0.999998        1  499999.000000
408   0.000003  0.999997  0.000000  ...  0.999997        1  333332.333333
2960  0.000006  0.999994  0.000000  ...  0.999994        1  166665.666667
2702  0.000006  0.999994  0.000000  ...  0.999994        1  166665.666667
...        ...       ...       ...  ...       ...      ...            ...
1844  0.003263  0.991121  0.000496  ...  0.991121        1     198.541867
695   0.005013  0.994452  0.000001  ...  0.994452        1     198.374626
452   0.005022  0.994813  0.000102  ...  0.994813        1     198.091000
2573  0.005043  0.994675  0.000086  ...  0.994675        1     197.238747
2333  0.005015  0.988224  0.000364  ...  0.988224        1     197.053639

[1034 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：197.053639 ~ 499999.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.483661
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：4.409056

** 3. 抽取的sample.csv形状为： 1034 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 290，加权重的“原始”频次区间为 69.183160 ~ 172.911463；已标准化：线性缩放

** 5. vertpool中共有 290 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5C09_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 17: 5C09_AC_DE_1E6 处理完成^_^
4JFD_AC_DE_a24b17
正在处理 4JFD_AC_DE_a24b17 ... 其TCR标签为 4 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 1500 次，正确预测 510 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
1218  0.000001  0.000001  0.000505  ...  0.998469        4  976.975538
1269  0.000000  0.000000  0.001111  ...  0.998426        4  898.673267
1491  0.000000  0.000000  0.001276  ...  0.997806        4  781.979624
1459  0.000000  0.000000  0.000526  ...  0.998034        4  695.009749
1195  0.000000  0.000000  0.001487  ...  0.998128        4  671.236046
...        ...       ...       ...  ...       ...      ...         ...
1062  0.000001  0.000000  0.006317  ...  0.991458        4  156.950768
1422  0.000003  0.000000  0.002796  ...  0.990872        4  156.833175
1320  0.000002  0.000000  0.004733  ...  0.988919        4  156.276707
1475  0.000000  0.000000  0.006447  ...  0.993151        4  154.048550
1194  0.000002  0.000000  0.005890  ...  0.987635        4  152.742809

[153 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 153 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 266，原始频次区间为 8 ~ 36；已标准化到[0, 1]区间

** 5. vertpool中共有 266 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 1500 次，正确预测 510 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
1218  0.000001  0.000001  0.000505  ...  0.998469        4  976.975538
1269  0.000000  0.000000  0.001111  ...  0.998426        4  898.673267
1491  0.000000  0.000000  0.001276  ...  0.997806        4  781.979624
1459  0.000000  0.000000  0.000526  ...  0.998034        4  695.009749
1195  0.000000  0.000000  0.001487  ...  0.998128        4  671.236046
...        ...       ...       ...  ...       ...      ...         ...
1062  0.000001  0.000000  0.006317  ...  0.991458        4  156.950768
1422  0.000003  0.000000  0.002796  ...  0.990872        4  156.833175
1320  0.000002  0.000000  0.004733  ...  0.988919        4  156.276707
1475  0.000000  0.000000  0.006447  ...  0.993151        4  154.048550
1194  0.000002  0.000000  0.005890  ...  0.987635        4  152.742809

[153 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：152.742809 ~ 976.975538
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.369019
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：1.446315

** 3. 抽取的sample.csv形状为： 153 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 266，加权重的“原始”频次区间为 7.455843 ~ 36.842324；已标准化：线性缩放

** 5. vertpool中共有 266 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//4JFD_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 18: 4JFD_AC_DE_a24b17 处理完成^_^
4JFE_AC_DE_a24b17
正在处理 4JFE_AC_DE_a24b17 ... 其TCR标签为 4 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 1836 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
1138  0.000375  0.000990  0.013830  ...  0.972390        4   70.310195
1042  0.000898  0.003121  0.017333  ...  0.951989        4   49.502834
1465  0.000428  0.012684  0.018624  ...  0.940663        4   44.096334
1217  0.000703  0.003902  0.029846  ...  0.944689        4   31.652114
1455  0.000307  0.002914  0.031277  ...  0.930458        4   29.748953
...        ...       ...       ...  ...       ...      ...         ...
2647  0.000932  0.000478  0.207217  ...  0.774199        4    3.736175
448   0.005117  0.023349  0.200843  ...  0.749836        4    3.733444
1400  0.005720  0.005135  0.108494  ...  0.689025        4    3.724943
1293  0.000922  0.051416  0.174129  ...  0.647101        4    3.716216
1201  0.002024  0.039432  0.047124  ...  0.674372        4    3.708152

[550 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 550 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 254，原始频次区间为 40 ~ 106；已标准化到[0, 1]区间

** 5. vertpool中共有 254 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 1836 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
1138  0.000375  0.000990  0.013830  ...  0.972390        4   70.310195
1042  0.000898  0.003121  0.017333  ...  0.951989        4   49.502834
1465  0.000428  0.012684  0.018624  ...  0.940663        4   44.096334
1217  0.000703  0.003902  0.029846  ...  0.944689        4   31.652114
1455  0.000307  0.002914  0.031277  ...  0.930458        4   29.748953
...        ...       ...       ...  ...       ...      ...         ...
2647  0.000932  0.000478  0.207217  ...  0.774199        4    3.736175
448   0.005117  0.023349  0.200843  ...  0.749836        4    3.733444
1400  0.005720  0.005135  0.108494  ...  0.689025        4    3.724943
1293  0.000922  0.051416  0.174129  ...  0.647101        4    3.716216
1201  0.002024  0.039432  0.047124  ...  0.674372        4    3.708152

[550 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3.708152 ~ 70.310195
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.245179
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：9.442108

** 3. 抽取的sample.csv形状为： 550 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 254，加权重的“原始”频次区间为 38.223996 ~ 107.895112；已标准化：线性缩放

** 5. vertpool中共有 254 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//4JFE_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 19: 4JFE_AC_DE_a24b17 处理完成^_^
4JFF_AC_DE_a24b17
正在处理 4JFF_AC_DE_a24b17 ... 其TCR标签为 4 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3107 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
2208  0.000003  0.000009  0.000223  ...  0.999383        4  4461.531250
945   0.000005  0.000328  0.000182  ...  0.999159        4  3046.216463
1627  0.000004  0.000013  0.000331  ...  0.999494        4  3019.619335
1792  0.000001  0.000056  0.000382  ...  0.999484        4  2616.450262
1578  0.000000  0.000028  0.000407  ...  0.999549        4  2455.894349
...        ...       ...       ...  ...       ...      ...          ...
1511  0.000004  0.000002  0.003126  ...  0.970719        4    37.359774
1897  0.000011  0.000007  0.025969  ...  0.969524        4    37.333898
2232  0.000001  0.000000  0.026127  ...  0.973584        4    37.263520
491   0.000005  0.000531  0.026113  ...  0.971965        4    37.221499
923   0.000015  0.000111  0.025660  ...  0.954736        4    37.207171

[932 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 932 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 262，原始频次区间为 82 ~ 186；已标准化到[0, 1]区间

** 5. vertpool中共有 262 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3107 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
2208  0.000003  0.000009  0.000223  ...  0.999383        4  4461.531250
945   0.000005  0.000328  0.000182  ...  0.999159        4  3046.216463
1627  0.000004  0.000013  0.000331  ...  0.999494        4  3019.619335
1792  0.000001  0.000056  0.000382  ...  0.999484        4  2616.450262
1578  0.000000  0.000028  0.000407  ...  0.999549        4  2455.894349
...        ...       ...       ...  ...       ...      ...          ...
1511  0.000004  0.000002  0.003126  ...  0.970719        4    37.359774
1897  0.000011  0.000007  0.025969  ...  0.969524        4    37.333898
2232  0.000001  0.000000  0.026127  ...  0.973584        4    37.263520
491   0.000005  0.000531  0.026113  ...  0.971965        4    37.221499
923   0.000015  0.000111  0.025660  ...  0.954736        4    37.207171

[932 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：37.207171 ~ 4461.531250
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.323585
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：3.756864

** 3. 抽取的sample.csv形状为： 932 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 262，加权重的“原始”频次区间为 77.900496 ~ 191.636893；已标准化：线性缩放

** 5. vertpool中共有 262 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//4JFF_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 20: 4JFF_AC_DE_a24b17 处理完成^_^
3D39_AC_DE_A6
正在处理 3D39_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 1000 次，正确预测 1000 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
            0         1         2  ...   max_val  max_idx     confidence
72   0.999983  0.000008  0.000000  ...  0.999983        0  111109.222222
102  0.999972  0.000013  0.000000  ...  0.999972        0   71426.571429
61   0.999980  0.000016  0.000000  ...  0.999980        0   62498.750000
423  0.999942  0.000015  0.000001  ...  0.999942        0   52628.526316
127  0.999968  0.000010  0.000000  ...  0.999968        0   45453.090909
..        ...       ...       ...  ...       ...      ...            ...
225  0.999656  0.000035  0.000001  ...  0.999656        0    3447.089655
271  0.999423  0.000238  0.000000  ...  0.999423        0    3434.443299
452  0.999584  0.000107  0.000002  ...  0.999584        0    3411.549488
156  0.999700  0.000005  0.000000  ...  0.999700        0    3400.340136
389  0.999546  0.000301  0.000004  ...  0.999546        0    3320.750831

[300 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 300 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 262，原始频次区间为 18 ~ 60；已标准化到[0, 1]区间

** 5. vertpool中共有 262 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 1000 次，正确预测 1000 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
            0         1         2  ...   max_val  max_idx     confidence
72   0.999983  0.000008  0.000000  ...  0.999983        0  111109.222222
102  0.999972  0.000013  0.000000  ...  0.999972        0   71426.571429
61   0.999980  0.000016  0.000000  ...  0.999980        0   62498.750000
423  0.999942  0.000015  0.000001  ...  0.999942        0   52628.526316
127  0.999968  0.000010  0.000000  ...  0.999968        0   45453.090909
..        ...       ...       ...  ...       ...      ...            ...
225  0.999656  0.000035  0.000001  ...  0.999656        0    3447.089655
271  0.999423  0.000238  0.000000  ...  0.999423        0    3434.443299
452  0.999584  0.000107  0.000002  ...  0.999584        0    3411.549488
156  0.999700  0.000005  0.000000  ...  0.999700        0    3400.340136
389  0.999546  0.000301  0.000004  ...  0.999546        0    3320.750831

[300 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3320.750831 ~ 111109.222222
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.432948
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：1.541797

** 3. 抽取的sample.csv形状为： 300 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 262，加权重的“原始”频次区间为 17.902069 ~ 59.119502；已标准化：线性缩放

** 5. vertpool中共有 262 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3D39_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 21: 3D39_AC_DE_A6 处理完成^_^
3D3V_AC_DE_A6
正在处理 3D3V_AC_DE_A6 ... 其TCR标签为 0 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2492 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
989   0.999988  0.000004  0.000003  ...  0.999988        0  249997.000000
764   0.999987  0.000008  0.000001  ...  0.999987        0  124998.375000
1110  0.999976  0.000001  0.000004  ...  0.999976        0   83331.333333
779   0.999967  0.000013  0.000004  ...  0.999967        0   76920.538462
1703  0.999969  0.000001  0.000000  ...  0.999969        0   58821.705882
...        ...       ...       ...  ...       ...      ...            ...
1511  0.997261  0.000007  0.000001  ...  0.997261        0    1028.104124
1418  0.997052  0.000668  0.000066  ...  0.997052        0    1027.888660
1709  0.998420  0.000024  0.000003  ...  0.998420        0    1027.181070
82    0.997923  0.000048  0.000012  ...  0.997923        0    1025.614594
248   0.998523  0.000028  0.000004  ...  0.998523        0    1024.126154

[747 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 747 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 265，原始频次区间为 56 ~ 132；已标准化到[0, 1]区间

** 5. vertpool中共有 265 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2492 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
989   0.999988  0.000004  0.000003  ...  0.999988        0  249997.000000
764   0.999987  0.000008  0.000001  ...  0.999987        0  124998.375000
1110  0.999976  0.000001  0.000004  ...  0.999976        0   83331.333333
779   0.999967  0.000013  0.000004  ...  0.999967        0   76920.538462
1703  0.999969  0.000001  0.000000  ...  0.999969        0   58821.705882
...        ...       ...       ...  ...       ...      ...            ...
1511  0.997261  0.000007  0.000001  ...  0.997261        0    1028.104124
1418  0.997052  0.000668  0.000066  ...  0.997052        0    1027.888660
1709  0.998420  0.000024  0.000003  ...  0.998420        0    1027.181070
82    0.997923  0.000048  0.000012  ...  0.997923        0    1025.614594
248   0.998523  0.000028  0.000004  ...  0.998523        0    1024.126154

[747 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：1024.126154 ~ 249997.000000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.793123
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.210289

** 3. 抽取的sample.csv形状为： 747 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 265，加权重的“原始”频次区间为 55.686436 ~ 132.351028；已标准化：线性缩放

** 5. vertpool中共有 265 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3D3V_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 22: 3D3V_AC_DE_A6 处理完成^_^
3UTS_AC_DE_1E6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 3UTS_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 2000 次，正确预测 1996 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1999  0.000000  0.999999  0.000000  ...  0.999999        1           inf
695   0.000000  1.000000  0.000000  ...  1.000000        1           inf
1705  0.000000  0.999999  0.000000  ...  0.999999        1           inf
1550  0.000000  1.000000  0.000000  ...  1.000000        1           inf
1547  0.000000  1.000000  0.000000  ...  1.000000        1           inf
...        ...       ...       ...  ...       ...      ...           ...
542   0.000003  0.999967  0.000023  ...  0.999967        1  4.347683e+04
981   0.000002  0.999962  0.000023  ...  0.999962        1  4.347661e+04
1986  0.000023  0.999960  0.000000  ...  0.999960        1  4.347652e+04
1794  0.000014  0.999951  0.000000  ...  0.999951        1  4.347613e+04
287   0.000022  0.999945  0.000000  ...  0.999945        1  4.347587e+04

[598 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 598 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 254，原始频次区间为 42 ~ 114；已标准化到[0, 1]区间

** 5. vertpool中共有 254 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 2000 次，正确预测 1996 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1999  0.000000  0.999999  0.000000  ...  0.999999        1           inf
695   0.000000  1.000000  0.000000  ...  1.000000        1           inf
1705  0.000000  0.999999  0.000000  ...  0.999999        1           inf
1550  0.000000  1.000000  0.000000  ...  1.000000        1           inf
1547  0.000000  1.000000  0.000000  ...  1.000000        1           inf
...        ...       ...       ...  ...       ...      ...           ...
542   0.000003  0.999967  0.000023  ...  0.999967        1  4.347683e+04
981   0.000002  0.999962  0.000023  ...  0.999962        1  4.347661e+04
1986  0.000023  0.999960  0.000000  ...  0.999960        1  4.347652e+04
1794  0.000014  0.999951  0.000000  ...  0.999951        1  4.347613e+04
287   0.000022  0.999945  0.000000  ...  0.999945        1  4.347587e+04

[598 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：43475.869565 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 598 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 254，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 254 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3UTS_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 23: 3UTS_AC_DE_1E6 处理完成^_^
3UTT_AC_DE_1E6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 3UTT_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2998 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
2805  0.000000  0.999999  0.000000  ...  0.999999        1          inf
2648  0.000000  1.000000  0.000000  ...  1.000000        1          inf
2887  0.000000  1.000000  0.000000  ...  1.000000        1          inf
2675  0.000000  0.999999  0.000000  ...  0.999999        1          inf
2633  0.000000  0.999999  0.000000  ...  0.999999        1          inf
...        ...       ...       ...  ...       ...      ...          ...
851   0.000137  0.999841  0.000015  ...  0.999841        1  7298.109489
673   0.000028  0.999828  0.000001  ...  0.999828        1  7298.014599
491   0.000011  0.999800  0.000137  ...  0.999800        1  7297.810219
2146  0.000137  0.999786  0.000045  ...  0.999786        1  7297.708029
690   0.000137  0.999754  0.000005  ...  0.999754        1  7297.474453

[899 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 899 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 228，原始频次区间为 86 ~ 179；已标准化到[0, 1]区间

** 5. vertpool中共有 228 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2998 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
2805  0.000000  0.999999  0.000000  ...  0.999999        1          inf
2648  0.000000  1.000000  0.000000  ...  1.000000        1          inf
2887  0.000000  1.000000  0.000000  ...  1.000000        1          inf
2675  0.000000  0.999999  0.000000  ...  0.999999        1          inf
2633  0.000000  0.999999  0.000000  ...  0.999999        1          inf
...        ...       ...       ...  ...       ...      ...          ...
851   0.000137  0.999841  0.000015  ...  0.999841        1  7298.109489
673   0.000028  0.999828  0.000001  ...  0.999828        1  7298.014599
491   0.000011  0.999800  0.000137  ...  0.999800        1  7297.810219
2146  0.000137  0.999786  0.000045  ...  0.999786        1  7297.708029
690   0.000137  0.999754  0.000005  ...  0.999754        1  7297.474453

[899 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：7297.474453 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 899 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 228，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 228 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3UTT_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 24: 3UTT_AC_DE_1E6 处理完成^_^
5C0A_AC_DE_1E6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 5C0A_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3488 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
244   0.000000  0.999999  0.000000  ...  0.999999        1           inf
2396  0.000000  1.000000  0.000000  ...  1.000000        1           inf
448   0.000000  1.000000  0.000000  ...  1.000000        1           inf
57    0.000000  0.999999  0.000000  ...  0.999999        1  9.999990e+05
420   0.000000  0.999999  0.000000  ...  0.999999        1  9.999990e+05
...        ...       ...       ...  ...       ...      ...           ...
1314  0.000004  0.999725  0.000001  ...  0.999725        1  3.744288e+03
928   0.000011  0.999721  0.000000  ...  0.999721        1  3.744273e+03
1287  0.000009  0.999721  0.000003  ...  0.999721        1  3.744273e+03
1146  0.000011  0.999721  0.000001  ...  0.999721        1  3.744273e+03
326   0.000040  0.999661  0.000004  ...  0.999661        1  3.744049e+03

[1046 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1046 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 315，原始频次区间为 65 ~ 168；已标准化到[0, 1]区间

** 5. vertpool中共有 315 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3488 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
244   0.000000  0.999999  0.000000  ...  0.999999        1           inf
2396  0.000000  1.000000  0.000000  ...  1.000000        1           inf
448   0.000000  1.000000  0.000000  ...  1.000000        1           inf
57    0.000000  0.999999  0.000000  ...  0.999999        1  9.999990e+05
420   0.000000  0.999999  0.000000  ...  0.999999        1  9.999990e+05
...        ...       ...       ...  ...       ...      ...           ...
1314  0.000004  0.999725  0.000001  ...  0.999725        1  3.744288e+03
928   0.000011  0.999721  0.000000  ...  0.999721        1  3.744273e+03
1287  0.000009  0.999721  0.000003  ...  0.999721        1  3.744273e+03
1146  0.000011  0.999721  0.000001  ...  0.999721        1  3.744273e+03
326   0.000040  0.999661  0.000004  ...  0.999661        1  3.744049e+03

[1046 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3744.048689 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 1046 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 315，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 315 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5C0A_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 25: 5C0A_AC_DE_1E6 处理完成^_^
5C0B_AC_DE_1E6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 5C0B_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3494 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
0     0.000000  1.000000  0.000000  ...  1.000000        1           inf
2342  0.000000  1.000000  0.000000  ...  1.000000        1           inf
2324  0.000000  1.000000  0.000000  ...  1.000000        1           inf
2326  0.000000  1.000000  0.000000  ...  1.000000        1           inf
2327  0.000000  1.000000  0.000000  ...  1.000000        1           inf
...        ...       ...       ...  ...       ...      ...           ...
879   0.000080  0.999883  0.000017  ...  0.999883        1  1.249854e+04
2283  0.000010  0.999882  0.000028  ...  0.999882        1  1.249852e+04
779   0.000080  0.999838  0.000017  ...  0.999838        1  1.249797e+04
475   0.000081  0.999916  0.000002  ...  0.999916        1  1.234464e+04
2312  0.000010  0.999903  0.000006  ...  0.999903        1  1.234448e+04

[1048 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1048 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 294，原始频次区间为 73 ~ 157；已标准化到[0, 1]区间

** 5. vertpool中共有 294 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3494 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
0     0.000000  1.000000  0.000000  ...  1.000000        1           inf
2342  0.000000  1.000000  0.000000  ...  1.000000        1           inf
2324  0.000000  1.000000  0.000000  ...  1.000000        1           inf
2326  0.000000  1.000000  0.000000  ...  1.000000        1           inf
2327  0.000000  1.000000  0.000000  ...  1.000000        1           inf
...        ...       ...       ...  ...       ...      ...           ...
879   0.000080  0.999883  0.000017  ...  0.999883        1  1.249854e+04
2283  0.000010  0.999882  0.000028  ...  0.999882        1  1.249852e+04
779   0.000080  0.999838  0.000017  ...  0.999838        1  1.249797e+04
475   0.000081  0.999916  0.000002  ...  0.999916        1  1.234464e+04
2312  0.000010  0.999903  0.000006  ...  0.999903        1  1.234448e+04

[1048 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：12344.481481 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 1048 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 294，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 294 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5C0B_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 26: 5C0B_AC_DE_1E6 处理完成^_^
5C0C_AC_IJ_1E6
正在处理 5C0C_AC_IJ_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 2001 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1949  0.000001  0.999959  0.000009  ...  0.999959        1  32256.741935
709   0.000062  0.999901  0.000003  ...  0.999901        1  16127.435484
881   0.000060  0.999862  0.000002  ...  0.999862        1  14082.563380
1968  0.000002  0.999893  0.000028  ...  0.999893        1  12985.623377
614   0.000007  0.999885  0.000007  ...  0.999885        1  10868.315217
...        ...       ...       ...  ...       ...      ...           ...
1614  0.001756  0.956101  0.003036  ...  0.956101        1     24.579696
505   0.000202  0.958662  0.000577  ...  0.958662        1     24.533896
1746  0.000065  0.933432  0.028407  ...  0.933432        1     24.509820
2450  0.000561  0.959846  0.000396  ...  0.959846        1     24.504621
661   0.001650  0.947528  0.038790  ...  0.947528        1     24.427120

[600 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 600 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 282，原始频次区间为 37 ~ 97；已标准化到[0, 1]区间

** 5. vertpool中共有 282 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 2001 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1949  0.000001  0.999959  0.000009  ...  0.999959        1  32256.741935
709   0.000062  0.999901  0.000003  ...  0.999901        1  16127.435484
881   0.000060  0.999862  0.000002  ...  0.999862        1  14082.563380
1968  0.000002  0.999893  0.000028  ...  0.999893        1  12985.623377
614   0.000007  0.999885  0.000007  ...  0.999885        1  10868.315217
...        ...       ...       ...  ...       ...      ...           ...
1614  0.001756  0.956101  0.003036  ...  0.956101        1     24.579696
505   0.000202  0.958662  0.000577  ...  0.958662        1     24.533896
1746  0.000065  0.933432  0.028407  ...  0.933432        1     24.509820
2450  0.000561  0.959846  0.000396  ...  0.959846        1     24.504621
661   0.001650  0.947528  0.038790  ...  0.947528        1     24.427120

[600 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：24.427120 ~ 32256.741935
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.248585
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：9.474316

** 3. 抽取的sample.csv形状为： 600 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 282，加权重的“原始”频次区间为 40.293254 ~ 106.963774；已标准化：线性缩放

** 5. vertpool中共有 282 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5C0C_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 27: 5C0C_AC_IJ_1E6 处理完成^_^
5C08_AC_DE_1E6
/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py:192: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x) / np.sum(np.exp(x), axis=0)
正在处理 5C08_AC_DE_1E6 ... 其TCR标签为 1 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2999 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
865   0.000000  1.000000  0.000000  ...  1.000000        1         inf
2100  0.000000  1.000000  0.000000  ...  1.000000        1         inf
2076  0.000000  1.000000  0.000000  ...  1.000000        1         inf
639   0.000000  0.999999  0.000000  ...  0.999999        1         inf
2083  0.000000  0.999999  0.000000  ...  0.999999        1         inf
...        ...       ...       ...  ...       ...      ...         ...
644   0.000001  0.999996  0.000001  ...  0.999996        1    499998.0
2020  0.000000  0.999996  0.000002  ...  0.999996        1    499998.0
625   0.000002  0.999996  0.000001  ...  0.999996        1    499998.0
1442  0.000002  0.999996  0.000001  ...  0.999996        1    499998.0
1370  0.000001  0.999996  0.000002  ...  0.999996        1    499998.0

[899 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 899 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 279，原始频次区间为 69 ~ 160；已标准化到[0, 1]区间

** 5. vertpool中共有 279 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 2999 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
865   0.000000  1.000000  0.000000  ...  1.000000        1         inf
2100  0.000000  1.000000  0.000000  ...  1.000000        1         inf
2076  0.000000  1.000000  0.000000  ...  1.000000        1         inf
639   0.000000  0.999999  0.000000  ...  0.999999        1         inf
2083  0.000000  0.999999  0.000000  ...  0.999999        1         inf
...        ...       ...       ...  ...       ...      ...         ...
644   0.000001  0.999996  0.000001  ...  0.999996        1    499998.0
2020  0.000000  0.999996  0.000002  ...  0.999996        1    499998.0
625   0.000002  0.999996  0.000001  ...  0.999996        1    499998.0
1442  0.000002  0.999996  0.000001  ...  0.999996        1    499998.0
1370  0.000001  0.999996  0.000002  ...  0.999996        1    499998.0

[899 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：499998.000000 ~ inf
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ inf
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：nan

** 3. 抽取的sample.csv形状为： 899 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 279，加权重的“原始”频次区间为 nan ~ nan；已标准化：线性缩放

** 5. vertpool中共有 279 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//5C08_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 28: 5C08_AC_DE_1E6 处理完成^_^
3QDJ_AC_DE_DMF5
正在处理 3QDJ_AC_DE_DMF5 ... 其TCR标签为 2 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2339 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
871   0.000000  0.000000  0.995780  ...  0.995780        2  282.250567
949   0.000002  0.000000  0.994315  ...  0.994315        2  240.288787
573   0.000000  0.000000  0.991915  ...  0.991915        2  239.940735
712   0.000007  0.000000  0.992713  ...  0.992713        2  239.092726
609   0.000002  0.000000  0.991649  ...  0.991649        2  226.507309
...        ...       ...       ...  ...       ...      ...         ...
1426  0.001092  0.000002  0.927159  ...  0.927159        2   22.715021
658   0.000000  0.000000  0.955225  ...  0.955225        2   22.696978
350   0.000090  0.000001  0.930163  ...  0.930163        2   22.642722
1026  0.000336  0.000000  0.951213  ...  0.951213        2   22.638226
1331  0.000430  0.000000  0.953389  ...  0.953389        2   22.621640

[701 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 701 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 231，原始频次区间为 68 ~ 131；已标准化到[0, 1]区间

** 5. vertpool中共有 231 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2339 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
871   0.000000  0.000000  0.995780  ...  0.995780        2  282.250567
949   0.000002  0.000000  0.994315  ...  0.994315        2  240.288787
573   0.000000  0.000000  0.991915  ...  0.991915        2  239.940735
712   0.000007  0.000000  0.992713  ...  0.992713        2  239.092726
609   0.000002  0.000000  0.991649  ...  0.991649        2  226.507309
...        ...       ...       ...  ...       ...      ...         ...
1426  0.001092  0.000002  0.927159  ...  0.927159        2   22.715021
658   0.000000  0.000000  0.955225  ...  0.955225        2   22.696978
350   0.000090  0.000001  0.930163  ...  0.930163        2   22.642722
1026  0.000336  0.000000  0.951213  ...  0.951213        2   22.638226
1331  0.000430  0.000000  0.953389  ...  0.953389        2   22.621640

[701 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：22.621640 ~ 282.250567
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.809222
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.246160

** 3. 抽取的sample.csv形状为： 701 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 231，加权重的“原始”频次区间为 66.511190 ~ 140.145464；已标准化：线性缩放

** 5. vertpool中共有 231 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3QDJ_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 29: 3QDJ_AC_DE_DMF5 处理完成^_^
6D78_AC_DE_DMF5
正在处理 6D78_AC_DE_DMF5 ... 其TCR标签为 2 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 2714 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
3104  0.000001  0.000000  0.999229  ...  0.999229        2  1685.040472
3482  0.000005  0.000000  0.999163  ...  0.999163        2  1596.107029
3036  0.000022  0.000000  0.998271  ...  0.998271        2   709.503198
2763  0.000000  0.000005  0.997610  ...  0.997610        2   702.047854
2507  0.000000  0.000001  0.996766  ...  0.996766        2   637.318414
...        ...       ...       ...  ...       ...      ...          ...
2826  0.000002  0.000020  0.924631  ...  0.924631        2    20.103296
3141  0.000071  0.000000  0.952100  ...  0.952100        2    20.078873
2669  0.000000  0.000011  0.946225  ...  0.946225        2    20.075211
3631  0.000018  0.000000  0.948632  ...  0.948632        2    20.049287
3550  0.000161  0.000000  0.949967  ...  0.949967        2    20.044881

[814 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 814 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 250，原始频次区间为 72 ~ 142；已标准化到[0, 1]区间

** 5. vertpool中共有 250 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 2714 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
3104  0.000001  0.000000  0.999229  ...  0.999229        2  1685.040472
3482  0.000005  0.000000  0.999163  ...  0.999163        2  1596.107029
3036  0.000022  0.000000  0.998271  ...  0.998271        2   709.503198
2763  0.000000  0.000005  0.997610  ...  0.997610        2   702.047854
2507  0.000000  0.000001  0.996766  ...  0.996766        2   637.318414
...        ...       ...       ...  ...       ...      ...          ...
2826  0.000002  0.000020  0.924631  ...  0.924631        2    20.103296
3141  0.000071  0.000000  0.952100  ...  0.952100        2    20.078873
2669  0.000000  0.000011  0.946225  ...  0.946225        2    20.075211
3631  0.000018  0.000000  0.948632  ...  0.948632        2    20.049287
3550  0.000161  0.000000  0.949967  ...  0.949967        2    20.044881

[814 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：20.044881 ~ 1685.040472
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.478189
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：4.384996

** 3. 抽取的sample.csv形状为： 814 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 250，加权重的“原始”频次区间为 72.189784 ~ 146.742637；已标准化：线性缩放

** 5. vertpool中共有 250 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6D78_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 30: 6D78_AC_DE_DMF5 处理完成^_^
3QDG_AC_DE_DMF5
正在处理 3QDG_AC_DE_DMF5 ... 其TCR标签为 2 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 163 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
951   0.000040  0.000000  0.853703  ...  0.853703        2    5.850968
2348  0.000004  0.000000  0.822136  ...  0.822136        2    4.971374
2174  0.000022  0.000000  0.773108  ...  0.773108        2    3.781959
2278  0.000024  0.000000  0.767570  ...  0.767570        2    3.498687
696   0.000065  0.000001  0.764822  ...  0.764822        2    3.268149
2078  0.000005  0.000000  0.753421  ...  0.753421        2    3.085869
667   0.000022  0.000000  0.750443  ...  0.750443        2    3.010853
1047  0.000002  0.000001  0.741484  ...  0.741484        2    2.874437
691   0.000032  0.000000  0.731745  ...  0.731745        2    2.731340
824   0.000047  0.000001  0.730818  ...  0.730818        2    2.720598
634   0.000044  0.000001  0.716836  ...  0.716836        2    2.665690
2142  0.000010  0.000000  0.712696  ...  0.712696        2    2.610694
810   0.000045  0.000001  0.715060  ...  0.715060        2    2.554497
703   0.000031  0.000000  0.710310  ...  0.710310        2    2.464608
579   0.000021  0.000000  0.696731  ...  0.696731        2    2.302178
967   0.000055  0.000001  0.690525  ...  0.690525        2    2.243909
46    0.000000  0.000000  0.683976  ...  0.683976        2    2.165194
907   0.000047  0.000000  0.681346  ...  0.681346        2    2.149689
774   0.000034  0.000001  0.677090  ...  0.677090        2    2.128404
1132  0.000015  0.000002  0.677209  ...  0.677209        2    2.124051
2406  0.000003  0.000000  0.672466  ...  0.672466        2    2.080489
1165  0.000020  0.000004  0.671949  ...  0.671949        2    2.077013
2054  0.000003  0.000000  0.671306  ...  0.671306        2    2.051067
679   0.000042  0.000001  0.671045  ...  0.671045        2    2.043128
1457  0.000004  0.000006  0.668627  ...  0.668627        2    2.031671
2177  0.000007  0.000000  0.661517  ...  0.661517        2    1.996382
751   0.000076  0.000000  0.656376  ...  0.656376        2    1.919396
2126  0.000025  0.000000  0.641868  ...  0.641868        2    1.909276
823   0.000036  0.000000  0.654259  ...  0.654259        2    1.894914
829   0.000029  0.000000  0.652574  ...  0.652574        2    1.881614
779   0.000049  0.000000  0.649707  ...  0.649707        2    1.863039
1487  0.000147  0.000003  0.644727  ...  0.644727        2    1.843805
1254  0.000002  0.000001  0.643525  ...  0.643525        2    1.808564
857   0.000071  0.000000  0.641941  ...  0.641941        2    1.797479
877   0.000057  0.000001  0.636592  ...  0.636592        2    1.775175
590   0.000091  0.000002  0.637872  ...  0.637872        2    1.768448
1934  0.000008  0.000000  0.623584  ...  0.623584        2    1.767989
2428  0.000009  0.000000  0.630829  ...  0.630829        2    1.765861
890   0.000148  0.000008  0.637351  ...  0.637351        2    1.762011
2390  0.000009  0.000000  0.632837  ...  0.632837        2    1.737160
1212  0.000001  0.000007  0.632400  ...  0.632400        2    1.722194
624   0.000064  0.000002  0.631016  ...  0.631016        2    1.716920
705   0.000036  0.000000  0.629338  ...  0.629338        2    1.701981
694   0.000051  0.000000  0.627313  ...  0.627313        2    1.700381
2236  0.000006  0.000000  0.627119  ...  0.627119        2    1.694678
633   0.000055  0.000001  0.625969  ...  0.625969        2    1.684247
2227  0.000004  0.000000  0.624769  ...  0.624769        2    1.682703
1406  0.000012  0.000023  0.625723  ...  0.625723        2    1.681897

[48 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 48 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 258，原始频次区间为 1 ~ 16；已标准化到[0, 1]区间

** 5. vertpool中共有 258 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3000 次，正确预测 163 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
951   0.000040  0.000000  0.853703  ...  0.853703        2    5.850968
2348  0.000004  0.000000  0.822136  ...  0.822136        2    4.971374
2174  0.000022  0.000000  0.773108  ...  0.773108        2    3.781959
2278  0.000024  0.000000  0.767570  ...  0.767570        2    3.498687
696   0.000065  0.000001  0.764822  ...  0.764822        2    3.268149
2078  0.000005  0.000000  0.753421  ...  0.753421        2    3.085869
667   0.000022  0.000000  0.750443  ...  0.750443        2    3.010853
1047  0.000002  0.000001  0.741484  ...  0.741484        2    2.874437
691   0.000032  0.000000  0.731745  ...  0.731745        2    2.731340
824   0.000047  0.000001  0.730818  ...  0.730818        2    2.720598
634   0.000044  0.000001  0.716836  ...  0.716836        2    2.665690
2142  0.000010  0.000000  0.712696  ...  0.712696        2    2.610694
810   0.000045  0.000001  0.715060  ...  0.715060        2    2.554497
703   0.000031  0.000000  0.710310  ...  0.710310        2    2.464608
579   0.000021  0.000000  0.696731  ...  0.696731        2    2.302178
967   0.000055  0.000001  0.690525  ...  0.690525        2    2.243909
46    0.000000  0.000000  0.683976  ...  0.683976        2    2.165194
907   0.000047  0.000000  0.681346  ...  0.681346        2    2.149689
774   0.000034  0.000001  0.677090  ...  0.677090        2    2.128404
1132  0.000015  0.000002  0.677209  ...  0.677209        2    2.124051
2406  0.000003  0.000000  0.672466  ...  0.672466        2    2.080489
1165  0.000020  0.000004  0.671949  ...  0.671949        2    2.077013
2054  0.000003  0.000000  0.671306  ...  0.671306        2    2.051067
679   0.000042  0.000001  0.671045  ...  0.671045        2    2.043128
1457  0.000004  0.000006  0.668627  ...  0.668627        2    2.031671
2177  0.000007  0.000000  0.661517  ...  0.661517        2    1.996382
751   0.000076  0.000000  0.656376  ...  0.656376        2    1.919396
2126  0.000025  0.000000  0.641868  ...  0.641868        2    1.909276
823   0.000036  0.000000  0.654259  ...  0.654259        2    1.894914
829   0.000029  0.000000  0.652574  ...  0.652574        2    1.881614
779   0.000049  0.000000  0.649707  ...  0.649707        2    1.863039
1487  0.000147  0.000003  0.644727  ...  0.644727        2    1.843805
1254  0.000002  0.000001  0.643525  ...  0.643525        2    1.808564
857   0.000071  0.000000  0.641941  ...  0.641941        2    1.797479
877   0.000057  0.000001  0.636592  ...  0.636592        2    1.775175
590   0.000091  0.000002  0.637872  ...  0.637872        2    1.768448
1934  0.000008  0.000000  0.623584  ...  0.623584        2    1.767989
2428  0.000009  0.000000  0.630829  ...  0.630829        2    1.765861
890   0.000148  0.000008  0.637351  ...  0.637351        2    1.762011
2390  0.000009  0.000000  0.632837  ...  0.632837        2    1.737160
1212  0.000001  0.000007  0.632400  ...  0.632400        2    1.722194
624   0.000064  0.000002  0.631016  ...  0.631016        2    1.716920
705   0.000036  0.000000  0.629338  ...  0.629338        2    1.701981
694   0.000051  0.000000  0.627313  ...  0.627313        2    1.700381
2236  0.000006  0.000000  0.627119  ...  0.627119        2    1.694678
633   0.000055  0.000001  0.625969  ...  0.625969        2    1.684247
2227  0.000004  0.000000  0.624769  ...  0.624769        2    1.682703
1406  0.000012  0.000023  0.625723  ...  0.625723        2    1.681897

[48 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：1.681897 ~ 5.850968
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.397827
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：10.999254

** 3. 抽取的sample.csv形状为： 48 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 258，加权重的“原始”频次区间为 0.491820 ~ 16.129773；已标准化：线性缩放

** 5. vertpool中共有 258 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//3QDG_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 31: 3QDG_AC_DE_DMF5 处理完成^_^
6DKP_AC_DE_DMF5
正在处理 6DKP_AC_DE_DMF5 ... 其TCR标签为 2 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4500 次，正确预测 1893 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
3903  0.000001  0.000000  0.989521  ...  0.989521        2  167.800746
3913  0.000000  0.000000  0.989635  ...  0.989635        2  156.069232
3581  0.000001  0.000000  0.986602  ...  0.986602        2  148.093966
3736  0.000001  0.000000  0.986286  ...  0.986286        2  131.452219
3547  0.000000  0.000000  0.987848  ...  0.987848        2  126.049254
...        ...       ...       ...  ...       ...      ...         ...
671   0.000001  0.000001  0.801017  ...  0.801017        2    4.037465
1351  0.000001  0.000003  0.796768  ...  0.796768        2    4.034636
3534  0.000017  0.000049  0.792768  ...  0.792768        2    4.021794
1347  0.000000  0.000002  0.796409  ...  0.796409        2    4.001412
3592  0.000005  0.000021  0.792690  ...  0.792690        2    3.967497

[567 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 567 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 269，原始频次区间为 31 ~ 107；已标准化到[0, 1]区间

** 5. vertpool中共有 269 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4500 次，正确预测 1893 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
3903  0.000001  0.000000  0.989521  ...  0.989521        2  167.800746
3913  0.000000  0.000000  0.989635  ...  0.989635        2  156.069232
3581  0.000001  0.000000  0.986602  ...  0.986602        2  148.093966
3736  0.000001  0.000000  0.986286  ...  0.986286        2  131.452219
3547  0.000000  0.000000  0.987848  ...  0.987848        2  126.049254
...        ...       ...       ...  ...       ...      ...         ...
671   0.000001  0.000001  0.801017  ...  0.801017        2    4.037465
1351  0.000001  0.000003  0.796768  ...  0.796768        2    4.034636
3534  0.000017  0.000049  0.792768  ...  0.792768        2    4.021794
1347  0.000000  0.000002  0.796409  ...  0.796409        2    4.001412
3592  0.000005  0.000021  0.792690  ...  0.792690        2    3.967497

[567 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3.967497 ~ 167.800746
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.717180
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：15.137574

** 3. 抽取的sample.csv形状为： 567 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 269，加权重的“原始”频次区间为 27.101407 ~ 124.540343；已标准化：线性缩放

** 5. vertpool中共有 269 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6DKP_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 32: 6DKP_AC_DE_DMF5 处理完成^_^
6AMU_AC_DE_DMF5
正在处理 6AMU_AC_DE_DMF5 ... 其TCR标签为 2 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 0 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
Empty DataFrame
Columns: [0, 1, 2, 3, 4, 5, 6, sec_val, max_val, max_idx, confidence]
Index: []

** 3. 抽取的sample.csv形状为： 0 行 * 32 列
Traceback (most recent call last):
  File "/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py", line 108, in <module>
    vert_impomin = min(sort_vimpo_dict.values())
ValueError: min() arg is an empty sequence
masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6AMU_AC.ply
Traceback (most recent call last):
  File "/home/alcohol/MyMaSIF_tolinux/source/data_preparation_pmhc/05-tracesurf.py", line 124, in <module>
    input_feat[pid], pool_index[pid], verts[pid], faces[pid], norms[pid] = read_pool_from_surface(ply_file[pid], params, csv_file[pid])
  File "/home/alcohol/MyMaSIF_tolinux/source/masif_modules/read_pool_from_surface.py", line 111, in read_pool_from_surface
    pool_index = pd.read_csv(csv_file, usecols=["vert_idx"])
  File "/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/usr/local/lib/python3.8/dist-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '../data/masif_pmhc/nn_models/test_set_predictions/trace_40-7_pepcut4_all-test//pool_6AMU.csv'
 33: 6AMU_AC_DE_DMF5 处理完成^_^
6AM5_AC_DE_DMF5
正在处理 6AM5_AC_DE_DMF5 ... 其TCR标签为 2 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 1146 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
2036  0.000236  0.000002  0.982234  ...  0.982234        2   60.031414
2240  0.000121  0.000002  0.977807  ...  0.977807        2   46.273579
2191  0.000088  0.000001  0.960849  ...  0.960849        2   41.658313
2017  0.000105  0.000000  0.970678  ...  0.970678        2   33.411744
2233  0.000079  0.000001  0.956946  ...  0.956946        2   32.524845
...        ...       ...       ...  ...       ...      ...         ...
2201  0.000277  0.000001  0.774031  ...  0.774031        2    3.442387
1626  0.004010  0.000000  0.726428  ...  0.726428        2    3.439413
2333  0.000489  0.000001  0.768576  ...  0.768576        2    3.429153
2483  0.001028  0.000003  0.747217  ...  0.747217        2    3.421981
2196  0.000566  0.000002  0.772482  ...  0.772482        2    3.421302

[343 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 343 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 245，原始频次区间为 24 ~ 74；已标准化到[0, 1]区间

** 5. vertpool中共有 245 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 1146 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
2036  0.000236  0.000002  0.982234  ...  0.982234        2   60.031414
2240  0.000121  0.000002  0.977807  ...  0.977807        2   46.273579
2191  0.000088  0.000001  0.960849  ...  0.960849        2   41.658313
2017  0.000105  0.000000  0.970678  ...  0.970678        2   33.411744
2233  0.000079  0.000001  0.956946  ...  0.956946        2   32.524845
...        ...       ...       ...  ...       ...      ...         ...
2201  0.000277  0.000001  0.774031  ...  0.774031        2    3.442387
1626  0.004010  0.000000  0.726428  ...  0.726428        2    3.439413
2333  0.000489  0.000001  0.768576  ...  0.768576        2    3.429153
2483  0.001028  0.000003  0.747217  ...  0.747217        2    3.421981
2196  0.000566  0.000002  0.772482  ...  0.772482        2    3.421302

[343 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3.421302 ~ 60.031414
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 3.329104
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：10.268736

** 3. 抽取的sample.csv形状为： 343 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 245，加权重的“原始”频次区间为 20.040570 ~ 80.038110；已标准化：线性缩放

** 5. vertpool中共有 245 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6AM5_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 34: 6AM5_AC_DE_DMF5 处理完成^_^
2VLJ_AC_DE_JM22
正在处理 2VLJ_AC_DE_JM22 ... 其TCR标签为 3 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3462 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2648  0.000001  0.000000  0.000006  ...  0.999979        3  124997.375000
2526  0.000016  0.000000  0.000015  ...  0.999934        3   47615.904762
2920  0.000033  0.000000  0.000064  ...  0.999803        3   15621.921875
2695  0.000017  0.000000  0.000070  ...  0.999881        3   14284.014286
2838  0.000003  0.000000  0.000079  ...  0.999894        3   12656.886076
...        ...       ...       ...  ...       ...      ...            ...
1835  0.003771  0.000002  0.006789  ...  0.989316        3     145.723376
1758  0.001262  0.000001  0.006865  ...  0.991784        3     144.469629
1550  0.002798  0.000011  0.006867  ...  0.989972        3     144.163681
1663  0.002688  0.000009  0.006874  ...  0.990116        3     144.037824
2455  0.000063  0.000000  0.006896  ...  0.992892        3     143.980858

[1038 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1038 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 239，原始频次区间为 101 ~ 193；已标准化到[0, 1]区间

** 5. vertpool中共有 239 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3462 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
2648  0.000001  0.000000  0.000006  ...  0.999979        3  124997.375000
2526  0.000016  0.000000  0.000015  ...  0.999934        3   47615.904762
2920  0.000033  0.000000  0.000064  ...  0.999803        3   15621.921875
2695  0.000017  0.000000  0.000070  ...  0.999881        3   14284.014286
2838  0.000003  0.000000  0.000079  ...  0.999894        3   12656.886076
...        ...       ...       ...  ...       ...      ...            ...
1835  0.003771  0.000002  0.006789  ...  0.989316        3     145.723376
1758  0.001262  0.000001  0.006865  ...  0.991784        3     144.469629
1550  0.002798  0.000011  0.006867  ...  0.989972        3     144.163681
1663  0.002688  0.000009  0.006874  ...  0.990116        3     144.037824
2455  0.000063  0.000000  0.006896  ...  0.992892        3     143.980858

[1038 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：143.980858 ~ 124997.375000
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.361530
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：3.902158

** 3. 抽取的sample.csv形状为： 1038 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 239，加权重的“原始”频次区间为 97.296287 ~ 194.853108；已标准化：线性缩放

** 5. vertpool中共有 239 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//2VLJ_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 35: 2VLJ_AC_DE_JM22 处理完成^_^
2VLK_AC_DE_JM22
正在处理 2VLK_AC_DE_JM22 ... 其TCR标签为 3 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 3902 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1942  0.000017  0.000000  0.000009  ...  0.999964        3  58821.411765
2184  0.000001  0.000000  0.000020  ...  0.999944        3  29410.117647
3536  0.000000  0.000000  0.000036  ...  0.999964        3  27776.777778
3987  0.000003  0.000000  0.000040  ...  0.999955        3  24998.875000
1979  0.000041  0.000000  0.000014  ...  0.999933        3  24388.609756
...        ...       ...       ...  ...       ...      ...           ...
1573  0.000807  0.000000  0.006214  ...  0.992576        3    159.732218
1444  0.001796  0.000003  0.006219  ...  0.991807        3    159.480142
1118  0.002159  0.000017  0.006220  ...  0.991204        3    159.357556
1183  0.002148  0.000010  0.006222  ...  0.991347        3    159.329315
3757  0.000014  0.000000  0.006238  ...  0.993712        3    159.299776

[1170 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1170 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 239，原始频次区间为 103 ~ 225；已标准化到[0, 1]区间

** 5. vertpool中共有 239 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 3902 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx    confidence
1942  0.000017  0.000000  0.000009  ...  0.999964        3  58821.411765
2184  0.000001  0.000000  0.000020  ...  0.999944        3  29410.117647
3536  0.000000  0.000000  0.000036  ...  0.999964        3  27776.777778
3987  0.000003  0.000000  0.000040  ...  0.999955        3  24998.875000
1979  0.000041  0.000000  0.000014  ...  0.999933        3  24388.609756
...        ...       ...       ...  ...       ...      ...           ...
1573  0.000807  0.000000  0.006214  ...  0.992576        3    159.732218
1444  0.001796  0.000003  0.006219  ...  0.991807        3    159.480142
1118  0.002159  0.000017  0.006220  ...  0.991204        3    159.357556
1183  0.002148  0.000010  0.006222  ...  0.991347        3    159.329315
3757  0.000014  0.000000  0.006238  ...  0.993712        3    159.299776

[1170 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：159.299776 ~ 58821.411765
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.165790
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：3.208456

** 3. 抽取的sample.csv形状为： 1170 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 239，加权重的“原始”频次区间为 102.016475 ~ 237.593000；已标准化：线性缩放

** 5. vertpool中共有 239 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//2VLK_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 36: 2VLK_AC_DE_JM22 处理完成^_^
6TMO_AC_DE_a24b17
正在处理 6TMO_AC_DE_a24b17 ... 其TCR标签为 4 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 1500 次，正确预测 1125 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
672   0.000002  0.002127  0.002217  ...  0.992338        4  311.272898
544   0.000001  0.001118  0.003506  ...  0.994595        4  283.683685
834   0.000006  0.000440  0.009178  ...  0.986846        4  107.522990
754   0.000000  0.000178  0.009823  ...  0.989742        4  100.757610
826   0.000000  0.000491  0.009889  ...  0.989416        4  100.052179
...        ...       ...       ...  ...       ...      ...         ...
1402  0.000174  0.000028  0.201309  ...  0.794065        4    3.944508
706   0.000002  0.000185  0.201867  ...  0.796251        4    3.944434
1365  0.000226  0.000065  0.191891  ...  0.755989        4    3.939679
913   0.000000  0.000080  0.202448  ...  0.797059        4    3.937105
918   0.000004  0.000057  0.199942  ...  0.786694        4    3.934611

[337 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 337 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 257，原始频次区间为 22 ~ 64；已标准化到[0, 1]区间

** 5. vertpool中共有 257 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 1500 次，正确预测 1125 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
672   0.000002  0.002127  0.002217  ...  0.992338        4  311.272898
544   0.000001  0.001118  0.003506  ...  0.994595        4  283.683685
834   0.000006  0.000440  0.009178  ...  0.986846        4  107.522990
754   0.000000  0.000178  0.009823  ...  0.989742        4  100.757610
826   0.000000  0.000491  0.009889  ...  0.989416        4  100.052179
...        ...       ...       ...  ...       ...      ...         ...
1402  0.000174  0.000028  0.201309  ...  0.794065        4    3.944508
706   0.000002  0.000185  0.201867  ...  0.796251        4    3.944434
1365  0.000226  0.000065  0.191891  ...  0.755989        4    3.939679
913   0.000000  0.000080  0.202448  ...  0.797059        4    3.937105
918   0.000004  0.000057  0.199942  ...  0.786694        4    3.934611

[337 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：3.934611 ~ 311.272898
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 4.190845
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：24.308962

** 3. 抽取的sample.csv形状为： 337 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 257，加权重的“原始”频次区间为 18.591471 ~ 78.406434；已标准化：线性缩放

** 5. vertpool中共有 257 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6TMO_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 37: 6TMO_AC_DE_a24b17 处理完成^_^
6VMC_AC_DE_T4H2
正在处理 6VMC_AC_DE_T4H2 ... 其TCR标签为 6 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 3989 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
203   0.000000  0.000000  0.000000  ...  0.999995        6  333331.666667
20    0.000001  0.000001  0.000000  ...  0.999992        6  249998.000000
475   0.000000  0.000000  0.000000  ...  0.999993        6  199998.600000
1789  0.000003  0.000005  0.000000  ...  0.999991        6  199998.200000
465   0.000000  0.000000  0.000000  ...  0.999989        6  199997.800000
...        ...       ...       ...  ...       ...      ...            ...
852   0.000022  0.000497  0.000002  ...  0.998289        6    1246.303371
200   0.000034  0.000806  0.000000  ...  0.998804        6    1239.210918
1209  0.000000  0.000816  0.000000  ...  0.999115        6    1224.405637
3371  0.000816  0.000332  0.000008  ...  0.997604        6    1222.553922
688   0.000002  0.000109  0.000000  ...  0.998926        6    1221.180929

[1196 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 1196 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 331，原始频次区间为 84 ~ 146；已标准化到[0, 1]区间

** 5. vertpool中共有 331 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 4000 次，正确预测 3989 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx     confidence
203   0.000000  0.000000  0.000000  ...  0.999995        6  333331.666667
20    0.000001  0.000001  0.000000  ...  0.999992        6  249998.000000
475   0.000000  0.000000  0.000000  ...  0.999993        6  199998.600000
1789  0.000003  0.000005  0.000000  ...  0.999991        6  199998.200000
465   0.000000  0.000000  0.000000  ...  0.999989        6  199997.800000
...        ...       ...       ...  ...       ...      ...            ...
852   0.000022  0.000497  0.000002  ...  0.998289        6    1246.303371
200   0.000034  0.000806  0.000000  ...  0.998804        6    1239.210918
1209  0.000000  0.000816  0.000000  ...  0.999115        6    1224.405637
3371  0.000816  0.000332  0.000008  ...  0.997604        6    1222.553922
688   0.000002  0.000109  0.000000  ...  0.998926        6    1221.180929

[1196 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：1221.180929 ~ 333331.666667
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 1.789203
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.201641

** 3. 抽取的sample.csv形状为： 1196 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 331，加权重的“原始”频次区间为 82.311832 ~ 148.423556；已标准化：线性缩放

** 5. vertpool中共有 331 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6VMC_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 38: 6VMC_AC_DE_T4H2 处理完成^_^
6VM9_AC_DE_T4H2
正在处理 6VM9_AC_DE_T4H2 ... 其TCR标签为 6 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2422 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
2189  0.000102  0.000007  0.000068  ...  0.999706        6  9801.039216
2139  0.000090  0.000013  0.000222  ...  0.999604        6  4502.720721
2442  0.000050  0.000040  0.000239  ...  0.999532        6  4182.142259
2124  0.000127  0.000022  0.000250  ...  0.999540        6  3998.160000
2285  0.000257  0.000010  0.000217  ...  0.999402        6  3888.723735
...        ...       ...       ...  ...       ...      ...          ...
2126  0.001408  0.000202  0.011846  ...  0.967053        6    81.635404
339   0.001433  0.012043  0.000008  ...  0.981963        6    81.538072
321   0.012098  0.002949  0.000005  ...  0.984183        6    81.350884
780   0.012001  0.000952  0.000361  ...  0.974601        6    81.209983
1855  0.000062  0.000471  0.000002  ...  0.986511        6    81.134222

[726 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 726 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 315，原始频次区间为 47 ~ 113；已标准化到[0, 1]区间

** 5. vertpool中共有 315 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 2500 次，正确预测 2422 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx   confidence
2189  0.000102  0.000007  0.000068  ...  0.999706        6  9801.039216
2139  0.000090  0.000013  0.000222  ...  0.999604        6  4502.720721
2442  0.000050  0.000040  0.000239  ...  0.999532        6  4182.142259
2124  0.000127  0.000022  0.000250  ...  0.999540        6  3998.160000
2285  0.000257  0.000010  0.000217  ...  0.999402        6  3888.723735
...        ...       ...       ...  ...       ...      ...          ...
2126  0.001408  0.000202  0.011846  ...  0.967053        6    81.635404
339   0.001433  0.012043  0.000008  ...  0.981963        6    81.538072
321   0.012098  0.002949  0.000005  ...  0.984183        6    81.350884
780   0.012001  0.000952  0.000361  ...  0.974601        6    81.209983
1855  0.000062  0.000471  0.000002  ...  0.986511        6    81.134222

[726 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：81.134222 ~ 9801.039216
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.090542
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.975888

** 3. 抽取的sample.csv形状为： 726 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 315，加权重的“原始”频次区间为 44.623618 ~ 114.978196；已标准化：线性缩放

** 5. vertpool中共有 315 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6VM9_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 39: 6VM9_AC_DE_T4H2 处理完成^_^
6VMA_AC_DE_T4H2
正在处理 6VMA_AC_DE_T4H2 ... 其TCR标签为 6 ... :)

------------------------- <<<不添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3044 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
2519  0.000840  0.002781  0.000031  ...  0.993819        6  357.360302
2618  0.001492  0.001316  0.000065  ...  0.993975        6  353.979701
2652  0.001383  0.002366  0.000043  ...  0.992537        6  308.337061
2892  0.002548  0.000840  0.000027  ...  0.992708        6  291.801293
3360  0.000015  0.000135  0.000108  ...  0.992787        6  287.931265
...        ...       ...       ...  ...       ...      ...         ...
1197  0.038977  0.002594  0.003984  ...  0.865039        6   18.433716
2702  0.050665  0.007315  0.000570  ...  0.933802        6   18.430909
557   0.024658  0.030543  0.011438  ...  0.870029        6   18.416820
571   0.001613  0.006678  0.000820  ...  0.901987        6   18.398886
609   0.017009  0.048201  0.012849  ...  0.885729        6   18.375739

[913 rows x 11 columns]

** 3. 抽取的sample.csv形状为： 913 行 * 32 列

** 4. 提取poolvert频次字典：vert数目为 266，原始频次区间为 56 ~ 163；已标准化到[0, 1]区间

** 5. vertpool中共有 266 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

------------------------- <<<添加权重>>> ---------------------------
** 1. 共采样 3500 次，正确预测 3044 次

** 2. 将logits.csv按照置信度排序，并抽取前30%：
             0         1         2  ...   max_val  max_idx  confidence
2519  0.000840  0.002781  0.000031  ...  0.993819        6  357.360302
2618  0.001492  0.001316  0.000065  ...  0.993975        6  353.979701
2652  0.001383  0.002366  0.000043  ...  0.992537        6  308.337061
2892  0.002548  0.000840  0.000027  ...  0.992708        6  291.801293
3360  0.000015  0.000135  0.000108  ...  0.992787        6  287.931265
...        ...       ...       ...  ...       ...      ...         ...
1197  0.038977  0.002594  0.003984  ...  0.865039        6   18.433716
2702  0.050665  0.007315  0.000570  ...  0.933802        6   18.430909
557   0.024658  0.030543  0.011438  ...  0.870029        6   18.416820
571   0.001613  0.006678  0.000820  ...  0.901987        6   18.398886
609   0.017009  0.048201  0.012849  ...  0.885729        6   18.375739

[913 rows x 11 columns]

*** 2a. 抽取的置信度取值范围：18.375739 ~ 357.360302
*** 2b. 将置信度以下界为底取对数，映射到：1.000000 ~ 2.019471
*** 2c. Softmax函数处理，得到归一化权重：权重差距为：2.771729

** 3. 抽取的sample.csv形状为： 913 行 * 32 列


** 4. 提取poolvert频次字典：vert数目为 266，加权重的“原始”频次区间为 53.645102 ~ 166.632225；已标准化：线性缩放

** 5. vertpool中共有 266 个vert，已写入pool.csv文件，处理完成:)

------------------------- <<< 完成 >>> ---------------------------

masif_pmhc
Reading data from input ply surface files.
data_preparation_pmhc/01-benchmark_surfaces//6VMA_AC.ply
------- WITHOUT weigh -------
Extracting pool sub-surf.
Storing feature-riched pool.ply.
--------- WITH weigh --------
Extracting weigh_pool sub-surf.
Storing feature-riched weigh_pool.ply.
 40: 6VMA_AC_DE_T4H2 处理完成^_^

Traceback (most recent call last):
  File "/home/alcohol/MyMaSIF_tolinux/source/trace_pmhc/extract_pool_importcsv_40-7_pepcut4.py", line 21, in <module>
    pdb_info = sys.argv[1] 
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/alcohol/MyMaSIF_tolinux/source/data_preparation_pmhc/05-tracesurf.py", line 32, in <module>
    print(sys.argv[2]) ## masif_pmhc
IndexError: list index out of range
 41:  处理完成^_^
